---
title: "LAB 4 - Linear regression with a single predictor"
author: "Emanuele"
date: "25/10/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Install the packages "DAAG", "MASS", "lattice"  ##

```{r}
# install.packages("DAAG")
# install.packages("MASS")
# install.packages("lattice")
```


## Example: roller data ###

### model fitting #

```{r}
library(DAAG)
roller.lm <- lm(depression ~ weight,data=roller)
attributes(roller.lm)
```


```{r}
plot(depression ~ weight, data = roller, 
     xlim=c(0,1.04*max(weight)),ylim=c(0,1.04*max(depression)),
     xlab = 'Weight of roller', ylab = 'Depression', pch = 16)

# creo un modello di reg lineare e disegno la retta
roller.lm <- lm(depression ~ weight, data=roller)
abline(roller.lm,col='red',lwd=2)

# aggiungo punti dei valori stimati
points(roller$weight,fitted.values(roller.lm), pch = 16, 
       col="red", lwd=2) 

# aggiungo gli scarti (diff. tra valore osservato e valore previsto secondo il modello)
segments(roller$weight, roller$depression, # start x,y (the actual value)
         roller$weight, fitted.values(roller.lm), # end x,y (the predicted value)
         
         col="blue", lwd=2)
```


```{r}
attributes(summary(roller.lm))

# summary <- funzione molto generale, aiuta a ottenere una sintesi per diversi oggetti
summary(roller.lm)
```

In ordine, osservo:
* min, max, quantili dei residui
* stima standard error, con statistica test e p-value per ipotesi alpha=0 e beta=0
* stima di sigma (sigma cappello), si indicano anche i gradi di libertà
* statistica test F, p-value coincide con test su beta. Serve a mettere in confronto il modello nullo (quello con solo alpha), con il modello generale (quello con anche beta)



Selezino elemento [2,2] della matrice (std.error di beta)
```{r}
SEb <- summary(roller.lm)$coefficients[2, 2]
SEb # beta
```

Intervallo di confidenza per beta a 95%. Sommo beta ai due quantili [...] moltiplicati per lo standard error
```{r}
coef(roller.lm)[2] + qt(c(0.025,.975), 8)*SEb
```


### confidence intervals and prediction intervals

```{r}
roller.lm$fitted.values


roller.pred <- 
  predict(roller.lm, # se gli passo l'lm in questo modo, userà come dataset "roller"
          se.fit=TRUE # calcolo anche gli standard error
          )

 
# roller.pred$fit # valori previsti (mu cappello)
# roller.pred$se.fit # standard error dei valori 

roller.pred

```

Nota: avendo applicato predict senza indicare new_data, ho usato i weight del dataset, dunque 
mi aspetto una corrispondeza tra i fitted value del modello e i valori predetti (ho applicato il modello agli stessi dati da cui è stato creato)


### Standard error di previsione

Calcolo l'SE di previsione sommando la varianza di mu cappello e la (stima della) varianza dell'errore.

```{r}
se.pred <- sqrt(roller.pred$se.fit^2+roller.pred$residual.scale^2)
se.pred
```

Osservo che lo standard error di previsione è diverso dallo standard error di stima, in quanto si introduce un errore epsilon. Ovviamente l'SE di previsione è molto più alto.


```{r}
# ----------------------------------------
# Step 1: scatterplot + retta di regressione
plot(depression ~ weight, data = roller, 
     xlim=c(0,1.04*max(weight)),ylim=c(0,1.04*max(depression)),
xlab = 'Weight of roller', ylab = 'Depression', pch = 16)
roller.lm <- lm(depression ~ weight,data=roller)
abline(roller.lm,col='red',lwd=2)


# ----------------------------------------
# Step 2: costruisco l'argomento "new data" (voglio una seq di valori 
# x da 1 a 13 spaziati di un int. [...] voglio applicare poi il modello su questi valori)
xy <- data.frame(weight = 
                   pretty(seq(1,13,1), 20) # metti 20 val equispaziati in un certo intervallo
                 )


# ----------------------------------------
# Step 3: intervalli di stima

# effettuo la prevsione su newdata
yhat <- predict(roller.lm, newdata = xy, 
                interval="confidence" # specifico che voglio gli int. di confidenza
                )

# estraggo gli intervalli di confidenza (df di due colonne con lower e upper bound)
ci <- data.frame(lower=yhat[, "lwr"], upper=yhat[, "upr"])

# disegno gli int. di confidenza (le bande) con come linee tratteggiate
lines(xy$weight, ci$lower, lty = 2, lwd=2, col="red")
lines(xy$weight, ci$upper, lty = 2, lwd=2, col="red")

# ----------------------------------------
# Step 4: intervalli di previsione

# ripeto la stessa cosa, solo che sta volta gli dico che voglio 
# gli intervali di PREVISIONE e non di stima
yhatob <- predict(roller.lm, newdata = xy, interval="prediction")
ciob <- data.frame(lower=yhatob[, "lwr"], upper=yhatob[, "upr"])
lines(xy$weight, ciob$lower, lty = 2, lwd=2)
lines(xy$weight, ciob$upper, lty = 2, lwd=2)

```

Osservo che gli intervalli di previsione (bande nero tratteggiato) sono più ampi di quelli di stima (bande rosso tratteggiato).

### diagnostic plots and aov table

```{r}
par(mfrow=c(1,2))
plot(roller.lm, which = 1, lwd=2, pch = 16, cex.caption=0.8)
plot(roller.lm, which = 2, xlab="Theoretical quantiles",
     lwd=2, pch = 16, cex.caption=0.8)
par(mfrow=c(1,1))
```


```{r}
par(mfrow=c(1,2))
plot(roller.lm, which = 3, lwd=2, pch = 16, cex.caption=0.8)
plot(roller.lm, which = 4, lwd=2, pch = 16, cex.caption=0.8)
par(mfrow=c(1,1))
```


```{r}
anova(roller.lm)
```

# Cosa posso fare se la variabile non è numerica ma categoriale?

## Example: paper resistance

x <- resistenza
y <- percentuale di fibra (la tratto come categoriale)

4 livelli
6 oss. per livello (caso bilanciato)

### ANOVA model

```{r}
library(lattice)
paper <- data.frame(resistance =
c(7, 8, 15,  11, 9, 10,# 5%
12, 17, 13, 18, 19, 15,# 10%
14, 18, 19, 17, 16, 18,# 15%
19, 25, 22, 23, 18, 20), # 20%
trt = rep(c("5%", "10%", "15%", "20%"),
c(6, 6, 6, 6)))
# paper$trt <- relevel(paper$trt, ref="5%")
paper$trt <- factor(paper$trt)
paper
```

Plot dei valori per gruppo
```{r}
stripplot(resistance~trt, aspect=0.6, data=paper, xlab="concentration", 
          ylab="resistance")
```


```{r}
# questo oggetto è sia modello che [...]
paper.aov <- aov(resistance~trt,data=paper) 


anova(paper.aov) # the same result is given by summary(paper.aov)
```

p-value basso <- ipotesi nulla scartata

(NOTA: in questo caso la categoria poteva essere anche trattata come variabile numerica)

```{r}
concentration <- c(5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 
                   15, 20, 20, 20, 20, 20, 20) # treatment specified as numeric vector
plot(paper$resistance ~ concentration,xlab = 'Concentration', ylab = 'Resistance', 
     xlim=c(3,22), ylim=c(4,27), pch = 16)
```


Essendo ... anche un oggetto di tipo lm, posso applicare summary e vedere tipico summary
```{r}
trt1 <- summary.lm(paper.aov)$coefficients[1,1] # mean first group
trt1
trt2 <- trt1 + summary.lm(paper.aov)$coefficients[2,1] # mean second group
trt2
trt3 <- trt1 + summary.lm(paper.aov)$coefficients[3,1] # mean third group
trt3 
trt4 <- trt1 + summary.lm(paper.aov)$coefficients[4,1] # mean fourth group
trt4

summary.lm(paper.aov)
```

* estimate Std. <- come varia la media da intercetta
* 

```{r}
concentration <- c(5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 
                   15, 20, 20, 20, 20, 20, 20) # treatment specified as numeric vector
plot(paper$resistance ~ concentration,xlab = 'Concentration', ylab = 'Resistance', 
     xlim=c(3,22), ylim=c(4,27), pch = 16)


points(c(5,10,15,20), c(trt1,trt2,trt3,trt4), col='red',lwd=2)
lines(c(5,10,15,20), c(trt1,trt2,trt3,trt4), col='red',lwd=2)
```


# # linear model with a factor predictor #
# 
# paper.lm1 <- lm(resistance ~ trt,data=paper)
# summary(paper.lm1)
# 
# concentration <- c(5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 15, 15, 15, 15, 15, 
#          15, 20, 20, 20, 20, 20, 20) # treatment specified as numeric vector
# plot(concentration,paper$resistance,xlab = 'Concentration', ylab = 'Resistance', 
#     xlim=c(3,22), ylim=c(4,27), pch = 16)
# points(c(5,10,15,20), 
#       c(paper.lm1$coef[1],paper.lm1$coef[1]+paper.lm1$coef[2],
#         paper.lm1$coef[1]+paper.lm1$coef[3],paper.lm1$coef[1]+
#           paper.lm1$coef[4]), col='red',lwd=2)
# lines(c(5,10,15,20), 
#       c(paper.lm1$coef[1],paper.lm1$coef[1]+paper.lm1$coef[2],
#         paper.lm1$coef[1]+paper.lm1$coef[3],paper.lm1$coef[1]+
#           paper.lm1$coef[4]), col='red',lwd=2)

# linear model #

```{r}
paper.lm2 <- lm(paper$resistance ~ concentration)
summary(paper.lm2)

plot(paper$resistance ~ concentration,xlab = 'Concentration', ylab = 'Resistance', 
     xlim=c(3,22), ylim=c(4,27), pch = 16)
abline(paper.lm2, col='blue',lwd=2)
points(c(5,10,15,20), c(trt1,trt2,trt3,trt4), col='red',lwd=2)
lines(c(5,10,15,20), c(trt1,trt2,trt3,trt4), col='red',lwd=2)
```

# Diagnostiche sui residui

## Example: cars

### model fitting

PRima cosa: stima mod lineare

```{r}
cars.lm <- lm(dist ~ speed, data = cars)
summary(cars.lm)
```

OSS:

* p-value suspeed molto basso => molto ragionevole pensare a beta != 0

Coincide con test F (particolarità del mod. di reg. lineare semplice, perchè c'è solo un regressore)

test F: "il modello ha solo l'intercetta"/"il modello ha un beta diverso da 0"

* vedo che ho R^2 e R^2 aggiustato



Ora disegno lo scatter-plot + disegno retta regressione:
```{r}
plot(dist ~ speed, data = cars, xlim=c(0,1.04*max(speed))
     ,ylim=c(0,1.04*max(dist)),xlab = 'Speed', ylab = 'Distance', pch = 16)
abline(cars.lm,col='red',lwd=2)
```


### diagnostic plots

```{r}

par(mfrow=c(2,2))
plot(cars.lm, which = 1, # quale grafico voglio considerare (li voglio uno alla volta)
     lwd=2, pch = 16, cex.caption=0.6)

plot(cars.lm, which = 3, lwd=2, pch = 16, cex.caption=0.6)
plot(cars.lm, which = 2, xlab="Theoretical quantiles",
     lwd=2, pch = 16, cex.caption=0.6)
plot(cars.lm, which = 4,lwd=2, pch = 16, cex.caption=0.6)

par(mfrow=c(2,2))
```




output con anche lowess (retta di regressione locale)
```{r}
plot(dist ~ speed, data = cars, xlim=c(0,1.04*max(speed)),
     ylim=c(0,1.04*max(dist)),
xlab = 'Speed', ylab = 'Distance', pch = 16)
abline(cars.lm,col='red',lwd=2)

# aggiungo regressione locale
with(cars, lines(lowess(dist ~ speed, 
                        f=.7 # determino lv. di smoothness (devo trovare buon equilibrio)
                        ), 
                 lwd=2, col='blue'))
```


### model with sqrt(dist)

Proviamo a lavorare su una trasf. di y (da prec ho osservato un andamento quadratico => radice di y)
```{r}
sqrtcars.lm <- lm(sqrt(dist) ~ speed, data = cars)
summary(cars.lm)
summary(sqrtcars.lm)
```

OSs. che R^2 cresce a 70% rispetto a modello lineare semplice



Con anova analizzo i due modelli (con y e sqrt(y))

```{r}
anova(cars.lm)
anova(sqrtcars.lm)
```

Cosa fa anova?

* mi analizza la varianza
* somma quadrati <- in col Sum Sq (in ordine su colonna: SST, SSE) 
[...]
* test F (per ogni beta) e P value <- modo alternativo per comparare modello nullo o modello con un beta


### diagnostic plots

```{r}
par(mfrow=c(1,2))
plot(sqrtcars.lm, which=1,lwd=2, pch = 16, cex.caption=0.6)
plot(sqrtcars.lm, which=2, xlab="Theoretical quantiles",
     lwd=2, pch = 16, cex.caption=0.6)

plot(sqrtcars.lm, which=3,lwd=2, pch = 16, cex.caption=0.6)
plot(sqrtcars.lm, which=4,lwd=2, pch = 16, cex.caption=0.6)
par(mfrow=c(1,1))
```


```{r}
plot(sqrt(dist) ~ speed, data = cars, xlim=c(3,26),
xlab = 'Speed', ylab = 'sqrt(Distance)', pch = 16)
abline(sqrtcars.lm,col='red',lwd=2)
with(cars, lines(lowess(sqrt(dist) ~ speed, f=.7), 
                 lwd=2, col='blue'))
```


### Box-Cox transformation

in MASS ho funz per ottenere un valore plausibile per lambda 

```{r}
library(MASS)
lambdares <- boxcox(cars.lm, lambda = seq(0, 1, 0.05))
```

Oss. che val ottimale è il massimo di questa, sulla quale prendo int. di confidenza del 95%

```{r}
lambdares <- boxcox(cars.lm, lambda = seq(0, 1, 0.05), 
                    
                    plotit=F, # no output grafico
                    
                    interp=F) # gli dico di "non infittire i valori", 
                              # altrimenti "infittisce" a 100 valori
                              # in queso modo ho i valori che ho fissato io


lambdares
```


### confidence and prediction intervals #

```{r}
# Step 1
plot(sqrt(dist) ~ speed, data = cars, xlim=c(2,27),
     ylim=c(0,1.04*max(sqrt(dist))), xlab = 'Speed', 
     ylab = 'sqrt(Distance)', pch = 16, main="Transfomed data set")
sqrtcars.lm <- lm(sqrt(dist) ~ speed, data=cars)
abline(sqrtcars.lm,col='red',lwd=2) # regression line
xy <- data.frame(speed = pretty(seq(2,28,1), 25))
yhat <- predict(sqrtcars.lm, newdata = xy, interval="confidence") # ci
ci <- data.frame(lower=yhat[, "lwr"], upper=yhat[, "upr"])
lines(xy$speed, ci$lower, lty = 2, lwd=2, col="red")
lines(xy$speed, ci$upper, lty = 2, lwd=2, col="red")
yhatob <- predict(sqrtcars.lm, newdata = xy, interval="prediction") # pi
ciob <- data.frame(lower=yhatob[, "lwr"], upper=yhatob[, "upr"])
lines(xy$speed, ciob$lower, lty = 2, lwd=2)
lines(xy$speed, ciob$upper, lty = 2, lwd=2)
# Step 2
xy <- data.frame(speed = pretty(seq(2,27,1), 25))
yhat <- predict(sqrtcars.lm, newdata = xy, interval="confidence")
yhat <- yhat^2 # converted ci
ci <- data.frame(lower=yhat[, "lwr"], upper=yhat[, "upr"])
yhatob <- predict(sqrtcars.lm, newdata = xy, interval="prediction")
yhatob <- yhatob^2 # converted pi
ciob <- data.frame(lower=yhatob[, "lwr"], upper=yhatob[, "upr"])

```



Per passare alla scala originale devo moltiplicare al quadrato le radici di y e di y stimate

```{r}
# Step 3
plot(dist ~ speed, data = cars, xlim=c(2,27),ylim=c(0,1.04*max(dist)), 
      xlab = 'Speed', ylab = 'Distance', pch = 16, 
      main="Original data set") # original scatterplot
lines(seq(2,27,0.05),(sqrtcars.lm$coefficients[1]+
      seq(2,27,0.05)*sqrtcars.lm$coefficients[2])^2,
      col='red',lwd=2) # converted regression line
lines(xy$speed, ci$lower, lty = 2, lwd=2, col="red") # converted ci
lines(xy$speed, ci$upper, lty = 2, lwd=2, col="red")
lines(xy$speed, ciob$lower, lty = 2, lwd=2) # converted pi
lines(xy$speed, ciob$upper, lty = 2, lwd=2)
```


NOTA: 

fare sta roba della scala non è proprio il massimo

nel ritorno nella scala originaria, la copertura non è così precisa


## Example: books ###

### model fitting

```{r}
library(DAAG)
softbacks.lm <- lm(weight ~ volume, data=softbacks)
plot(softbacks$volume[-c(4,6)], softbacks$weight[-c(4,6)], xlab = 'Volume', 
     ylab = 'Weight', xlim=c(370,1520), ylim=c(230,1100), pch = 16)
points(softbacks$volume[4], softbacks$weight[4], pch=16, lwd=2, col='red')
points(softbacks$volume[6], softbacks$weight[6], pch=16, lwd=2, col='blue')
abline(softbacks.lm,col='red',lwd=2)
```


```{r}
summary(softbacks.lm)
```


### diagnostic plots

```{r}
par(mfrow=c(1,2))
plot(softbacks.lm, which = 1, lwd=2, pch = 16, cex.caption=0.7)
plot(softbacks.lm, which = 4, lwd=2, pch = 16, cex.caption=0.7)
par(mfrow=c(1,1))

```


* Oss. distanze di cook elevate per 4 e 6
* 4 è leva perché si trova molto in là
* 



Facciamo un po' di analisi di come varia la retta togliendo ciascun punto 

```{r}
softbacks.lm <- lm(weight ~ volume, data=softbacks)
plot(softbacks$volume[-c(4,6)], softbacks$weight[-c(4,6)], 
     xlab = 'Volume', ylab = 'Weight', xlim=c(370,1520), 
     ylim=c(230,1100), pch = 16)
points(softbacks$volume[4], softbacks$weight[4], pch=16, 
       lwd=2, col='red')
points(softbacks$volume[6], softbacks$weight[6], pch=16, 
       lwd=2, col='blue')
abline(softbacks.lm,col='black',lwd=2)



for(i in 1:8)
{
  # print modello senza il punto i
  # (colore nero, oppure rosso o blu per i=4 e i=6)
  cols <- 'black'
  cols <- ifelse(i==4, 'red', cols)
  cols <- ifelse(i==6, 'blue', cols)
  mod <- lm(weight ~ volume, data=softbacks[-i,])
  abline(mod, lty=2, lwd=2, col=cols)
}
```


Togliendo rossi e blu (4 e 6) vedo che retta varia molto 
=> 4 e 6 sono punti influenti 

* rosso <- produce maggiore influenza
* blu <- influenza leggermente minore 

(nonostante blu sia leva)


# Commento finale

valutazioni solo se il problema ci permette di lavorare in modo "artigianale"

eg, Machine Learning <- non si riesce a fare tutto questo trattamento









